{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.6.6"
    },
    "colab": {
      "name": "Copia di DL4CV - 2.1 - Architecture Modeule VGG.ipynb",
      "provenance": []
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qeUV6Jp4aJf_"
      },
      "source": [
        "# **Welcome!**\n",
        "\n",
        "# Introduction to Machine Learning for Computer Vision\n",
        "\n",
        "#### Deeper Architectures:  Visual Geometry Group Network [VGG]\n",
        "\n",
        "\n",
        "## **Lecturer :** Matteo Alberti\n",
        "\n",
        "![](data:image/jpeg;base64,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)\n",
        "\n",
        "*Contacts :* https://www.linkedin.com/in/matteo-alberti-170493/\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zTx_Et6haD0Q"
      },
      "source": [
        "# Summary\n",
        "\n",
        "- <font color=C24024>**Deep Convolutional Neural Networks** </font> : [VGG Net]\n",
        "\n",
        "- <font color=CA4A2F>**Hands-On** </font> : from Paper to Code\n",
        "\n",
        "- <font color=F4C52D>**Exercises & Tips** </font>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_BwjPMCmaD0W"
      },
      "source": [
        "Paper : [VERY DEEP CONVOLUTIONAL NETWORKS\n",
        "FOR LARGE-SCALE IMAGE RECOGNITION, Karen Simonyan & Andrew Zisserman+](https://github.com/matteoalberti/Lectures_introCV_Experis2020/blob/main/docs/VGG.pdf)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7IfR1F_SaD0Y"
      },
      "source": [
        "#Sklearn ML\n",
        "from sklearn.model_selection import train_test_split\n",
        "from skimage.transform import resize\n",
        "import numpy as np\n",
        "\n",
        "#TF Imports\n",
        "import tensorflow as tf\n",
        "import sklearn.model_selection as model_selection\n",
        "import datetime\n",
        "\n",
        "\n",
        "#Visualization\n",
        "import matplotlib.pyplot as plt\n",
        "plt.style.use('seaborn-white')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Yd9apjNKaD0i"
      },
      "source": [
        "input_shape = (224, 224, 3)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SR37xofmaD0r"
      },
      "source": [
        "#Instantiate an empty model\n",
        "\n",
        "def build_VGG(input_shape, n_classes):\n",
        "  return tf.keras.models.Sequential([    \n",
        "  tf.keras.layers.Conv2D(64, (3, 3), input_shape=input_shape, padding='same', activation='relu'),\n",
        "  tf.keras.layers.Conv2D(64, (3, 3), activation='relu', padding='same'),\n",
        "  tf.keras.layers.MaxPooling2D(pool_size=(2, 2), strides=(2, 2)),\n",
        "  tf.keras.layers.Conv2D(128, (3, 3), activation='relu', padding='same'),\n",
        "  tf.keras.layers.Conv2D(128, (3, 3), activation='relu', padding='same',),\n",
        "  tf.keras.layers.MaxPooling2D(pool_size=(2, 2), strides=(2, 2)),\n",
        "  tf.keras.layers.Conv2D(256, (3, 3), activation='relu', padding='same',),\n",
        "  tf.keras.layers.Conv2D(256, (3, 3), activation='relu', padding='same',),\n",
        "  tf.keras.layers.Conv2D(256, (3, 3), activation='relu', padding='same',),\n",
        "  tf.keras.layers.MaxPooling2D(pool_size=(2, 2), strides=(2, 2)),\n",
        "  tf.keras.layers.Conv2D(512, (3, 3), activation='relu', padding='same',),\n",
        "  tf.keras.layers.Conv2D(512, (3, 3), activation='relu', padding='same',),\n",
        "  tf.keras.layers.Conv2D(512, (3, 3), activation='relu', padding='same',),\n",
        "  tf.keras.layers.MaxPooling2D(pool_size=(2, 2), strides=(2, 2)),\n",
        "  tf.keras.layers.Conv2D(512, (3, 3), activation='relu', padding='same',),\n",
        "  tf.keras.layers.Conv2D(512, (3, 3), activation='relu', padding='same',),\n",
        "  tf.keras.layers.Conv2D(512, (3, 3), activation='relu', padding='same',),\n",
        "  tf.keras.layers.MaxPooling2D(pool_size=(2, 2), strides=(2, 2)),\n",
        "  tf.keras.layers.Flatten(),\n",
        "  tf.keras.layers.Dense(4096, activation='relu'),\n",
        "  tf.keras.layers.Dense(4096, activation='relu'),\n",
        "  tf.keras.layers.Dense(n_classes, activation='softmax')])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fDiBhsTmuvOy",
        "outputId": "1869a398-177b-4d58-dabf-cb05046345da",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 963
        }
      },
      "source": [
        "#Define\n",
        "VGG_model = build_VGG(input_shape=input_shape, n_classes=1000)\n",
        "\n",
        "#Compile architecture\n",
        "VGG_model.compile(optimizer='adam',\n",
        "              loss='sparse_categorical_crossentropy',\n",
        "              metrics=['accuracy'])\n",
        "\n",
        "#Show\n",
        "VGG_model.summary()\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model: \"sequential\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "conv2d (Conv2D)              (None, 224, 224, 64)      1792      \n",
            "_________________________________________________________________\n",
            "conv2d_1 (Conv2D)            (None, 224, 224, 64)      36928     \n",
            "_________________________________________________________________\n",
            "max_pooling2d (MaxPooling2D) (None, 112, 112, 64)      0         \n",
            "_________________________________________________________________\n",
            "conv2d_2 (Conv2D)            (None, 112, 112, 128)     73856     \n",
            "_________________________________________________________________\n",
            "conv2d_3 (Conv2D)            (None, 112, 112, 128)     147584    \n",
            "_________________________________________________________________\n",
            "max_pooling2d_1 (MaxPooling2 (None, 56, 56, 128)       0         \n",
            "_________________________________________________________________\n",
            "conv2d_4 (Conv2D)            (None, 56, 56, 256)       295168    \n",
            "_________________________________________________________________\n",
            "conv2d_5 (Conv2D)            (None, 56, 56, 256)       590080    \n",
            "_________________________________________________________________\n",
            "conv2d_6 (Conv2D)            (None, 56, 56, 256)       590080    \n",
            "_________________________________________________________________\n",
            "max_pooling2d_2 (MaxPooling2 (None, 28, 28, 256)       0         \n",
            "_________________________________________________________________\n",
            "conv2d_7 (Conv2D)            (None, 28, 28, 512)       1180160   \n",
            "_________________________________________________________________\n",
            "conv2d_8 (Conv2D)            (None, 28, 28, 512)       2359808   \n",
            "_________________________________________________________________\n",
            "conv2d_9 (Conv2D)            (None, 28, 28, 512)       2359808   \n",
            "_________________________________________________________________\n",
            "max_pooling2d_3 (MaxPooling2 (None, 14, 14, 512)       0         \n",
            "_________________________________________________________________\n",
            "conv2d_10 (Conv2D)           (None, 14, 14, 512)       2359808   \n",
            "_________________________________________________________________\n",
            "conv2d_11 (Conv2D)           (None, 14, 14, 512)       2359808   \n",
            "_________________________________________________________________\n",
            "conv2d_12 (Conv2D)           (None, 14, 14, 512)       2359808   \n",
            "_________________________________________________________________\n",
            "max_pooling2d_4 (MaxPooling2 (None, 7, 7, 512)         0         \n",
            "_________________________________________________________________\n",
            "flatten (Flatten)            (None, 25088)             0         \n",
            "_________________________________________________________________\n",
            "dense (Dense)                (None, 4096)              102764544 \n",
            "_________________________________________________________________\n",
            "dense_1 (Dense)              (None, 4096)              16781312  \n",
            "_________________________________________________________________\n",
            "dense_2 (Dense)              (None, 1000)              4097000   \n",
            "=================================================================\n",
            "Total params: 138,357,544\n",
            "Trainable params: 138,357,544\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1njOTrHNvZvS"
      },
      "source": [
        "# Adapt an architecture to our Domain!\n",
        "\n",
        "*You can choose between Cifar10, Cifar100 or MNIST from tf.keras.datasets*\n",
        "\n",
        "Or you can try with local data loading and solve step-by-step each problem!"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "i-hdnCx8aD0x"
      },
      "source": [
        "## Test on Cifar10"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rBSLaJ3iaD0y",
        "outputId": "eeed8168-53fb-40d5-c56f-b65025f7ba37",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 72
        }
      },
      "source": [
        "(x_train, y_train), (x_test, y_test) = tf.keras.datasets.cifar10.load_data()\n",
        "\n",
        "print(x_train.shape, y_train.shape, x_test.shape, y_test.shape)\n",
        "\n",
        "#The range for each individual colour is 0-255\n",
        "x_train = x_train.astype('float32')/255 \n",
        "x_test = x_test.astype('float32')/255"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Downloading data from https://www.cs.toronto.edu/~kriz/cifar-10-python.tar.gz\n",
            "170500096/170498071 [==============================] - 4s 0us/step\n",
            "(50000, 32, 32, 3) (50000, 1) (10000, 32, 32, 3) (10000, 1)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Q-BZS-FjaD02"
      },
      "source": [
        "input_shape = (32, 32, 3)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Nxv0nRzSaD06",
        "outputId": "9bc3064c-286a-42fc-e1ee-b5326ba59329",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 963
        }
      },
      "source": [
        "# Define Model\n",
        "VGG_model = build_VGG(input_shape=input_shape, n_classes=10)\n",
        "\n",
        "#Compile architecture\n",
        "VGG_model.compile(optimizer='adam',\n",
        "              loss='sparse_categorical_crossentropy',\n",
        "              metrics=['accuracy'])\n",
        "\n",
        "#Show\n",
        "VGG_model.summary()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model: \"sequential_1\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "conv2d_13 (Conv2D)           (None, 32, 32, 64)        1792      \n",
            "_________________________________________________________________\n",
            "conv2d_14 (Conv2D)           (None, 32, 32, 64)        36928     \n",
            "_________________________________________________________________\n",
            "max_pooling2d_5 (MaxPooling2 (None, 16, 16, 64)        0         \n",
            "_________________________________________________________________\n",
            "conv2d_15 (Conv2D)           (None, 16, 16, 128)       73856     \n",
            "_________________________________________________________________\n",
            "conv2d_16 (Conv2D)           (None, 16, 16, 128)       147584    \n",
            "_________________________________________________________________\n",
            "max_pooling2d_6 (MaxPooling2 (None, 8, 8, 128)         0         \n",
            "_________________________________________________________________\n",
            "conv2d_17 (Conv2D)           (None, 8, 8, 256)         295168    \n",
            "_________________________________________________________________\n",
            "conv2d_18 (Conv2D)           (None, 8, 8, 256)         590080    \n",
            "_________________________________________________________________\n",
            "conv2d_19 (Conv2D)           (None, 8, 8, 256)         590080    \n",
            "_________________________________________________________________\n",
            "max_pooling2d_7 (MaxPooling2 (None, 4, 4, 256)         0         \n",
            "_________________________________________________________________\n",
            "conv2d_20 (Conv2D)           (None, 4, 4, 512)         1180160   \n",
            "_________________________________________________________________\n",
            "conv2d_21 (Conv2D)           (None, 4, 4, 512)         2359808   \n",
            "_________________________________________________________________\n",
            "conv2d_22 (Conv2D)           (None, 4, 4, 512)         2359808   \n",
            "_________________________________________________________________\n",
            "max_pooling2d_8 (MaxPooling2 (None, 2, 2, 512)         0         \n",
            "_________________________________________________________________\n",
            "conv2d_23 (Conv2D)           (None, 2, 2, 512)         2359808   \n",
            "_________________________________________________________________\n",
            "conv2d_24 (Conv2D)           (None, 2, 2, 512)         2359808   \n",
            "_________________________________________________________________\n",
            "conv2d_25 (Conv2D)           (None, 2, 2, 512)         2359808   \n",
            "_________________________________________________________________\n",
            "max_pooling2d_9 (MaxPooling2 (None, 1, 1, 512)         0         \n",
            "_________________________________________________________________\n",
            "flatten_1 (Flatten)          (None, 512)               0         \n",
            "_________________________________________________________________\n",
            "dense_3 (Dense)              (None, 4096)              2101248   \n",
            "_________________________________________________________________\n",
            "dense_4 (Dense)              (None, 4096)              16781312  \n",
            "_________________________________________________________________\n",
            "dense_5 (Dense)              (None, 10)                40970     \n",
            "=================================================================\n",
            "Total params: 33,638,218\n",
            "Trainable params: 33,638,218\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fytTmM-rxUig"
      },
      "source": [
        "# define callbacks\n",
        "\n",
        "%load_ext tensorboard\n",
        "log_dir = \"logs/fit/\" + datetime.datetime.now().strftime(\"%Y%m%d-%H%M%S\")\n",
        "tensorboard_callback = tf.keras.callbacks.TensorBoard(log_dir=log_dir, histogram_freq=1)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5g4N1aGeaD1M",
        "outputId": "4a09a64a-eae0-479d-fd8e-df962a9f2445",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 255
        }
      },
      "source": [
        "# start train \n",
        "history_VGG = VGG_model.fit(x=x_train, \n",
        "          y=y_train, \n",
        "          epochs=5,\n",
        "          validation_split=0.2, \n",
        "          callbacks=[tensorboard_callback], verbose=1)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/5\n",
            "   1/1250 [..............................] - ETA: 0s - loss: 2.3026 - accuracy: 0.1250WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow/python/ops/summary_ops_v2.py:1277: stop (from tensorflow.python.eager.profiler) is deprecated and will be removed after 2020-07-01.\n",
            "Instructions for updating:\n",
            "use `tf.profiler.experimental.stop` instead.\n",
            "   2/1250 [..............................] - ETA: 55s - loss: 2.3050 - accuracy: 0.0625WARNING:tensorflow:Callbacks method `on_train_batch_end` is slow compared to the batch time (batch time: 0.0140s vs `on_train_batch_end` time: 0.0737s). Check your callbacks.\n",
            "1250/1250 [==============================] - 43s 35ms/step - loss: 2.3029 - accuracy: 0.0971 - val_loss: 2.3027 - val_accuracy: 0.0997\n",
            "Epoch 2/5\n",
            "1250/1250 [==============================] - 43s 35ms/step - loss: 2.3028 - accuracy: 0.0975 - val_loss: 2.3027 - val_accuracy: 0.0952\n",
            "Epoch 3/5\n",
            "1250/1250 [==============================] - 44s 35ms/step - loss: 2.3027 - accuracy: 0.0972 - val_loss: 2.3030 - val_accuracy: 0.0952\n",
            "Epoch 4/5\n",
            " 277/1250 [=====>........................] - ETA: 30s - loss: 2.3026 - accuracy: 0.1019"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sg70yJEoxsK0"
      },
      "source": [
        "# Evaluate \n",
        "score = VGG_model.evaluate(x_test, y_test, verbose=0)\n",
        "print(score[0], ' : loss')\n",
        "print(score[1]*100, '% : acc')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TLTuEkyFjBKs"
      },
      "source": [
        "from sklearn.metrics import plot_confusion_matrix\n",
        "from sklearn.metrics import confusion_matrix"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "goGBNI3QiwEh"
      },
      "source": [
        "# Predict the labels of the test set samples\n",
        "predicted_labels = VGG_model.predict(x_test)\n",
        "\n",
        "# Build the confusion matrix of our 10-class classification problem\n",
        "cnf_matrix = confusion_matrix(y_test, predicted_labels)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4dGgl-qujEUH"
      },
      "source": [
        "class_names = ['airplane', 'automobile', 'bird', 'cat', 'deer',\n",
        "               'dog', 'frog', 'horse', 'ship', 'truck']\n",
        "               \n",
        "disp = plot_confusion_matrix(VGG_model, x_test, y_test,\n",
        "                                 display_labels=class_names,\n",
        "                                 cmap=plt.cm.Blues)\n",
        "plt.show()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "E0PQ1f67aD1P"
      },
      "source": [
        "def plot_model_history(model_history):\n",
        "    fig, axs = plt.subplots(1,2,figsize=(15,5))\n",
        "    # summarize history for accuracy\n",
        "    axs[0].plot(range(1,len(model_history.history['accuracy'])+1),model_history.history['accuracy'])\n",
        "    axs[0].plot(range(1,len(model_history.history['val_accuracy'])+1),model_history.history['val_accuracy'])\n",
        "    axs[0].set_title('Model Accuracy')\n",
        "    axs[0].set_ylabel('Accuracy')\n",
        "    axs[0].set_xlabel('Epoch')\n",
        "    axs[0].set_xticks(np.arange(1,len(model_history.history['accuracy'])+1),len(model_history.history['accuracy'])/10)\n",
        "    axs[0].legend(['train', 'val'], loc='best')\n",
        "    # summarize history for loss\n",
        "    axs[1].plot(range(1,len(model_history.history['loss'])+1),model_history.history['loss'])\n",
        "    axs[1].plot(range(1,len(model_history.history['val_loss'])+1),model_history.history['val_loss'])\n",
        "    axs[1].set_title('Model Loss')\n",
        "    axs[1].set_ylabel('Loss')\n",
        "    axs[1].set_xlabel('Epoch')\n",
        "    axs[1].set_xticks(np.arange(1,len(model_history.history['loss'])+1),len(model_history.history['loss'])/10)\n",
        "    axs[1].legend(['train', 'val'], loc='best')\n",
        "    plt.show()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MxxCw8p-aD1T"
      },
      "source": [
        "plot_model_history(history_VGG)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KlXX_o0uaD1W",
        "outputId": "415733b2-e13b-4a0f-aae6-d32e5842d278",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 389
        }
      },
      "source": [
        "labelNames = np.array(['airplane', 'automobile', 'bird', 'cat', 'deer', 'dog', 'frog', 'horse', 'ship', 'truck'])\n",
        "\n",
        "# How CNN Classifies an Image?\n",
        "img_idx = 3\n",
        "plt.imshow(x_test[img_idx],aspect='auto')\n",
        "print('Actual label:', labelNames[np.argmax(y_test[img_idx])])\n",
        "# Preper image to predict\n",
        "test_image =np.expand_dims(x_test[img_idx], axis=0)\n",
        "print('Input image shape:',test_image.shape)\n",
        "print('Predict Label:',labelNames[VGG_model.predict_classes(test_image,batch_size=1)[0]])\n",
        "print('\\nPredict Probability:\\n', VGG_model.predict(test_image,batch_size=1))\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Actual label: airplane\n",
            "Input image shape: (1, 32, 32, 3)\n",
            "Predict Label: bird\n",
            "\n",
            "Predict Probability:\n",
            " [[0.09841129 0.10012601 0.10212573 0.09881639 0.09948608 0.0990797\n",
            "  0.10160124 0.10070214 0.0996961  0.09995529]]\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "U8MLoazsaD1f"
      },
      "source": [
        "## Notes :\n",
        "\n",
        "- The padding is chosen as 1 pixel so the spatial resolution is preserved through the convolutional layers. Thus, the spatial resolution will only change at the pooling layers\n",
        "- The pooling layer does not learn anything\n",
        "- fully-connected layers : Activation size previous layer * Activation size actual layer + 1"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "aNILEFY-aD1k"
      },
      "source": [
        "### Do you want to check other VGG Net configurations easly?\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "S3F2Q_9SaD1p"
      },
      "source": [
        "vgg16 = tf.keras.applications.VGG16(\n",
        "    include_top=True, weights='imagenet', input_tensor=None, input_shape=None,\n",
        "    pooling=None, classes=1000, classifier_activation='softmax')\n",
        "\n",
        "vgg16.summary()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3gMQGz2NwwC0"
      },
      "source": [
        "### Parameters :\n",
        "\n",
        "https://www.tensorflow.org/api_docs/python/tf/keras/applications/VGG16"
      ]
    }
  ]
}